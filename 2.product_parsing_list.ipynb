{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08ed400f-5572-4d88-a4e2-a8f3ae054cc7",
   "metadata": {},
   "source": [
    "# 각 선제품의 링크별 댓글들을 크롤링하는 코드입니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15d7045f-3efe-4b92-8c2b-752e84a778fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import csv\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from itertools import zip_longest\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b36d7c78-675f-47f1-ad16-48dfe6c9ab09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():# 선제품 링크 url 불러오기\n",
    "    data = []\n",
    "    with open(\"./crawling_data/suncream_link.csv\") as fr:\n",
    "        reader = csv.DictReader(fr)\n",
    "        for row in reader:\n",
    "            data.append(row)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28ded1ef-b38d-4a9e-8007-7f84062d0268",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_data(data):# 제품 데이터 수집\n",
    "    file_path = \"./data/suncream_review.csv\"\n",
    "    file_exists = os.path.isfile(\"./data/total_reviews.csv\")\n",
    "    \n",
    "    with open(file_path, \"a\", newline='', encoding='utf-8') as fw:\n",
    "        writer = csv.DictWriter(fw, fieldnames=[\"page\", \"product_name\", \"title\", \"review\",\"skin_type\",\"score\"])\n",
    "        \n",
    "        # 파일이 존재하지 않으면 헤더를 작성\n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "        \n",
    "        for row in data:\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "830c7119-5255-4a40-bb30-e064855a673c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(url):# 파싱하여 필요한 데이터 추출\n",
    "    \n",
    "    driver = webdriver.Chrome()\n",
    "    \n",
    "    try:\n",
    "        driver.get(url)\n",
    "        WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"reviewInfo\"]'))).click()\n",
    "        time.sleep(5)\n",
    "\n",
    "        for page_num in range(1, 200):\n",
    "            parse_review_text_list = []\n",
    "            html = driver.page_source\n",
    "            soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "            product_name_tag = soup.find(\"p\", class_=\"prd_name\")\n",
    "            product_name = product_name_tag.text if product_name_tag else []\n",
    "\n",
    "            user_clrfix_tags = soup.find_all(\"div\", class_=\"user clrfix\")\n",
    "            review_tags = soup.find_all(\"div\", class_=\"txt_inner\")# 제품 리뷰 댓글\n",
    "            title_tags = soup.find_all(\"div\", class_=\"poll_sample\")# 리뷰 제목\n",
    "            score_tags = soup.find_all(\"span\", class_=\"point\")# 평점\n",
    "            combined_list = list(zip_longest(title_tags,score_tags, review_tags, user_clrfix_tags, fillvalue=None))\n",
    "\n",
    "            for title_tag, score_tag, review_tag, user_clrfix_tag in combined_list:\n",
    "                review_text = review_tag.text if review_tag else None\n",
    "                title_text = [tag.text.strip() for tag in title_tag.find_all(\"span\")[1::2]] if title_tag else None\n",
    "                span_texts = [span.text.strip() for span in user_clrfix_tag.find_all(\"span\")[1:]] if user_clrfix_tag else None\n",
    "                score_texts = [score_tag.text.strip() if score_tag else None]\n",
    "                review_data = {\n",
    "                    \"page\": page_num,\n",
    "                    \"product_name\": product_name,\n",
    "                    \"title\": title_text,\n",
    "                    \"review\": review_text,\n",
    "                    \"skin_type\": span_texts,\n",
    "                    \"score\": score_texts\n",
    "                }\n",
    "                parse_review_text_list.append(review_data)\n",
    "\n",
    "            write_data(parse_review_text_list)\n",
    "\n",
    "            try:# 리뷰 페이지 넘기기\n",
    "                next_button = driver.find_element(By.XPATH, f\"//a[@data-page-no='{page_num + 1}']\")\n",
    "                next_button.click()\n",
    "                time.sleep(5)\n",
    "            except NoSuchElementException:\n",
    "                print(f\"Page {page_num} is the last page. \\n \")\n",
    "                break\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n",
    "    \n",
    "    return parse_review_text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bf50e3-88e0-4935-9563-f942302ad084",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':# 최종 크롤링 실행\n",
    "    data = load_data()\n",
    "    parse_review_list = []\n",
    "    \n",
    "    for i, review in enumerate(data):\n",
    "        url = review[\"product_link\"]\n",
    "        try:\n",
    "            parse_review = parse_data(url)\n",
    "        except:\n",
    "            continue\n",
    "        print(f\"{i}번 제품 끝\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022985bf-64d0-4548-a219-de9a63da9ba9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
